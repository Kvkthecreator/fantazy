"""
Deterministic Content Workflow Endpoint

Part of Workflow-First Architecture:
- Explicit parameters (no TP orchestration)
- Direct specialist invocation via ContentAgent or GeminiContentAgent
- Full context loading (brand voice, prior content)
- Auditable execution tracking
- Optional recipe-driven execution (parameterized templates)

Architecture:
- Multi-provider support via get_content_agent() factory
- Default: GeminiContentAgent (text + image generation)
- Fallback: ContentAgent (Anthropic, text only)
- Work-oriented context: brand voice, prior content, target audience
- Tool execution via emit_work_output for supervision workflow
"""

from typing import Optional, Dict, Any, List
from uuid import UUID
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from datetime import datetime, timezone

from app.utils.jwt import verify_jwt
from app.utils.supabase_client import supabase_admin_client as supabase
from agents import get_content_agent
from services.recipe_loader import RecipeLoader, RecipeValidationError
import logging
import time

router = APIRouter(prefix="/work/content", tags=["workflows"])
logger = logging.getLogger(__name__)


class ContentWorkflowRequest(BaseModel):
    """Deterministic content workflow parameters."""
    basket_id: str
    task_description: str
    content_type: Optional[str] = "linkedin_post"  # linkedin_post, twitter_thread, twitter_post, instagram_caption, blog_article
    tone: Optional[str] = "professional"  # professional, casual, authoritative, friendly, inspiring
    target_audience: Optional[str] = None
    brand_voice: Optional[str] = None
    create_variants: Optional[bool] = False
    variant_count: Optional[int] = 2
    enable_web_search: Optional[bool] = False
    priority: Optional[int] = 5

    # Image generation (Gemini only)
    include_image: Optional[bool] = None  # Auto-determined if None
    image_style: Optional[str] = "modern professional"  # Style for generated images

    # Provider selection
    provider: Optional[str] = None  # "gemini" (default) or "anthropic"

    # Recipe integration (optional)
    recipe_id: Optional[str] = None  # Recipe UUID or slug
    recipe_parameters: Optional[Dict[str, Any]] = None  # User-customized parameters
    reference_asset_ids: Optional[List[str]] = None  # User-uploaded assets

    # Async execution mode
    async_execution: Optional[bool] = False  # If True, return ticket_id immediately


class ContentWorkflowResponse(BaseModel):
    """Content workflow execution result."""
    work_request_id: str
    work_ticket_id: str
    status: str  # pending, running, completed, failed
    outputs: List[dict]  # work_outputs generated by agent
    execution_time_ms: Optional[int]
    message: str
    recipe_used: Optional[str] = None  # Recipe slug if recipe-driven
    token_usage: Optional[Dict[str, int]] = None  # Token usage stats


@router.post("/execute", response_model=ContentWorkflowResponse)
async def execute_content_workflow(
    request: ContentWorkflowRequest,
    user: dict = Depends(verify_jwt)
):
    """
    Execute deterministic content workflow.

    Flow:
    1. Validate permissions (workspace, basket)
    2. Create work_request + work_ticket (tracking)
    3. Execute ContentAgent with context
    4. Return structured outputs

    Args:
        request: Content workflow parameters
        user: Authenticated user from JWT

    Returns:
        Content workflow execution result with outputs

    Raises:
        401: Authentication failed
        403: Permission denied
        404: Basket or recipe not found
        400: Invalid recipe parameters
        500: Execution error
    """
    user_id = user.get("sub") or user.get("user_id")
    user_token = user.get("token")  # JWT for substrate-API auth
    if not user_id:
        raise HTTPException(status_code=401, detail="Invalid user token")

    logger.info(
        f"[CONTENT WORKFLOW] Starting: user={user_id}, basket={request.basket_id}, "
        f"type={request.content_type}, recipe={request.recipe_id}"
    )

    try:
        # Step 1: Validate basket access and get workspace
        basket_response = supabase.table("baskets").select(
            "id, workspace_id, name"
        ).eq("id", request.basket_id).single().execute()

        if not basket_response.data:
            raise HTTPException(status_code=404, detail="Basket not found")

        basket = basket_response.data
        workspace_id = basket["workspace_id"]

        # Step 2: Recipe-driven execution (if recipe_id provided)
        recipe = None
        execution_context = None
        validated_params = None

        if request.recipe_id:
            logger.info(f"[CONTENT WORKFLOW] Loading recipe: {request.recipe_id}")

            loader = RecipeLoader()

            # Load recipe by ID or slug
            try:
                recipe = await loader.load_recipe(recipe_id=request.recipe_id)
            except Exception:
                recipe = await loader.load_recipe(slug=request.recipe_id)

            logger.info(f"[CONTENT WORKFLOW] Loaded recipe: {recipe.name} (v{recipe.version})")

            # Validate parameters
            try:
                validated_params = loader.validate_parameters(
                    recipe=recipe,
                    user_parameters=request.recipe_parameters or {}
                )
                logger.info(f"[CONTENT WORKFLOW] Validated parameters: {validated_params}")
            except RecipeValidationError as e:
                raise HTTPException(
                    status_code=400,
                    detail=f"Recipe parameter validation failed: {str(e)}"
                )

            # Generate execution context
            execution_context = loader.generate_execution_context(
                recipe=recipe,
                validated_parameters=validated_params
            )

        # Step 3: Create work_request (for tracking & billing)
        work_request_data = {
            "workspace_id": workspace_id,
            "basket_id": request.basket_id,
            "requested_by_user_id": user_id,
            "request_type": f"recipe_{recipe.slug}" if recipe else "content_workflow",
            "task_intent": recipe.name if recipe else request.task_description,
            "parameters": {
                "content_type": request.content_type,
                "tone": request.tone,
                "target_audience": request.target_audience,
                "create_variants": request.create_variants,
                "variant_count": request.variant_count,
                "recipe_used": recipe.slug if recipe else None,
                "recipe_parameters": validated_params if recipe else None,
            },
            "priority": "normal",
        }

        if recipe:
            work_request_data["recipe_id"] = recipe.id
            work_request_data["recipe_parameters"] = validated_params
            work_request_data["reference_asset_ids"] = request.reference_asset_ids or []

        work_request_response = supabase.table("work_requests").insert(
            work_request_data
        ).execute()
        work_request_id = work_request_response.data[0]["id"]

        # Step 4: Create work_ticket (execution tracking)
        work_ticket_data = {
            "work_request_id": work_request_id,
            "workspace_id": workspace_id,
            "basket_id": request.basket_id,
            "agent_type": "content",
            "status": "pending",
            "metadata": {
                "workflow": "recipe_content" if recipe else "deterministic_content",
                "task_description": request.task_description,
                "content_type": request.content_type,
                "tone": request.tone,
                "recipe_slug": recipe.slug if recipe else None,
                "recipe_id": recipe.id if recipe else None,
                "execution_mode": "direct_api",  # Mark as using new executor
            },
        }
        work_ticket_response = supabase.table("work_tickets").insert(
            work_ticket_data
        ).execute()
        work_ticket_id = work_ticket_response.data[0]["id"]

        logger.info(
            f"[CONTENT WORKFLOW] Created: work_request={work_request_id}, "
            f"work_ticket={work_ticket_id}"
        )

        # ASYNC MODE: Return immediately, execute in background
        if request.async_execution:
            logger.info(f"[CONTENT WORKFLOW] Async mode: returning ticket_id immediately")

            import threading
            import asyncio as bg_asyncio

            # Capture closure variables
            _basket_id = request.basket_id
            _workspace_id = workspace_id
            _user_id = user_id
            _user_token = user_token
            _work_request_id = work_request_id
            _work_ticket_id = work_ticket_id
            _task_description = request.task_description
            _content_type = request.content_type
            _tone = request.tone
            _target_audience = request.target_audience
            _brand_voice = request.brand_voice
            _create_variants = request.create_variants
            _variant_count = request.variant_count
            _enable_web_search = request.enable_web_search
            _include_image = request.include_image  # Gemini image generation
            _image_style = request.image_style
            _provider = request.provider  # Provider selection (gemini/anthropic)
            _recipe = recipe
            _execution_context = execution_context
            _validated_params = validated_params

            def execute_in_background():
                logger.info(f"[CONTENT WORKFLOW] Background thread started for ticket {_work_ticket_id}")

                # Create a new event loop for this thread
                loop = bg_asyncio.new_event_loop()
                bg_asyncio.set_event_loop(loop)
                logger.info(f"[CONTENT WORKFLOW] Event loop created")

                try:
                    from app.utils.supabase_client import supabase_admin_client as bg_supabase
                    from agents.content_agent import ContentAgent
                    from app.work.task_streaming import emit_task_update
                    logger.info(f"[CONTENT WORKFLOW] Imports successful")

                    # Update status to running
                    bg_supabase.table("work_tickets").update({
                        "status": "running",
                        "started_at": datetime.now(timezone.utc).isoformat(),
                    }).eq("id", _work_ticket_id).execute()
                    logger.info(f"[CONTENT WORKFLOW] Ticket status updated to running")

                    # Emit initial task update
                    emit_task_update(_work_ticket_id, {
                        "type": "task_started",
                        "status": "in_progress",
                        "current_step": "Initializing content generation",
                        "activeForm": "Setting up content agent",
                    })
                    logger.info(f"[CONTENT WORKFLOW] Emitted task_started")

                    # Build enhanced task if recipe-driven
                    enhanced_task = _task_description
                    if _execution_context:
                        task_breakdown = _execution_context.get("task_breakdown", [])
                        deliverable_intent = _execution_context.get("deliverable_intent", {})
                        enhanced_task = f"""**Recipe: {_recipe.name}**

**Deliverable Intent:**
- Purpose: {deliverable_intent.get('purpose', 'Create content')}
- Audience: {deliverable_intent.get('audience', 'Target audience')}
- Outcome: {deliverable_intent.get('outcome', 'Quality content')}

**Task:** {_task_description}

**Task Breakdown:**
{chr(10).join([f"- {step}" for step in task_breakdown])}

**Parameters:**
- Platform: {_validated_params.get('platform', _content_type) if _validated_params else _content_type}
- Tone: {_validated_params.get('tone', _tone) if _validated_params else _tone}
- Topic: {_validated_params.get('topic_focus', _task_description) if _validated_params else _task_description}

{_execution_context.get('system_prompt_additions', '')}
"""

                    # Emit context loading update
                    emit_task_update(_work_ticket_id, {
                        "type": "task_update",
                        "status": "in_progress",
                        "current_step": "Loading context",
                        "activeForm": "Loading brand voice and prior content",
                    })

                    # Create executor via factory (Gemini or Anthropic)
                    from agents import get_content_agent
                    from agents.gemini_content_agent import GeminiContentAgent
                    executor = get_content_agent(
                        basket_id=_basket_id,
                        workspace_id=_workspace_id,
                        work_ticket_id=_work_ticket_id,
                        user_id=_user_id,
                        user_jwt=_user_token,
                        provider=_provider,
                    )

                    # Emit generation update
                    emit_task_update(_work_ticket_id, {
                        "type": "task_update",
                        "status": "in_progress",
                        "current_step": "Generating content",
                        "activeForm": f"Creating {_content_type} content",
                    })

                    start_time = time.time()

                    # Execute based on provider type
                    if isinstance(executor, GeminiContentAgent):
                        result = loop.run_until_complete(executor.execute(
                            task=enhanced_task,
                            content_type=_content_type,
                            tone=_tone,
                            target_audience=_target_audience,
                            brand_voice=_brand_voice,
                            include_image=_include_image,
                            image_style=_image_style,
                            create_variants=_create_variants,
                            variant_count=_variant_count,
                        ))
                    else:
                        result = loop.run_until_complete(executor.execute(
                            task=enhanced_task,
                            content_type=_content_type,
                            tone=_tone,
                            target_audience=_target_audience,
                            brand_voice=_brand_voice,
                            create_variants=_create_variants,
                            variant_count=_variant_count,
                            enable_web_search=_enable_web_search,
                        ))
                    execution_time_ms = int((time.time() - start_time) * 1000)

                    # Emit completion update
                    emit_task_update(_work_ticket_id, {
                        "type": "task_completed",
                        "status": "completed",
                        "current_step": "Content generation complete",
                        "activeForm": f"Generated {len(result.work_outputs)} outputs",
                        "output_count": len(result.work_outputs),
                    })

                    # Update to completed
                    existing_ticket = bg_supabase.table("work_tickets").select("metadata").eq("id", _work_ticket_id).single().execute()
                    existing_metadata = existing_ticket.data.get("metadata", {}) if existing_ticket.data else {}

                    updated_metadata = {
                        **existing_metadata,
                        "execution_time_ms": execution_time_ms,
                        "output_count": len(result.work_outputs),
                        "token_usage": {
                            "input_tokens": result.input_tokens,
                            "output_tokens": result.output_tokens,
                            "cache_read_tokens": result.cache_read_tokens,
                        },
                    }

                    bg_supabase.table("work_tickets").update({
                        "status": "completed",
                        "completed_at": datetime.now(timezone.utc).isoformat(),
                        "metadata": updated_metadata,
                    }).eq("id", _work_ticket_id).execute()

                    logger.info(f"[CONTENT WORKFLOW] Background complete: {len(result.work_outputs)} outputs")

                except Exception as e:
                    logger.exception(f"[CONTENT WORKFLOW] Background execution failed: {e}")
                    import traceback
                    logger.error(f"[CONTENT WORKFLOW] Traceback: {traceback.format_exc()}")
                    try:
                        from app.utils.supabase_client import supabase_admin_client as err_supabase
                        from app.work.task_streaming import emit_task_update as emit_err

                        # Emit error update
                        emit_err(_work_ticket_id, {
                            "type": "task_failed",
                            "status": "failed",
                            "current_step": "Execution failed",
                            "activeForm": str(e)[:100],
                            "error": str(e),
                        })

                        err_supabase.table("work_tickets").update({
                            "status": "failed",
                            "completed_at": datetime.now(timezone.utc).isoformat(),
                            "error_message": str(e),
                        }).eq("id", _work_ticket_id).execute()
                        logger.info(f"[CONTENT WORKFLOW] Updated ticket to failed status")
                    except Exception as update_err:
                        logger.error(f"[CONTENT WORKFLOW] Failed to update ticket: {update_err}")
                finally:
                    # Clean up the event loop
                    logger.info(f"[CONTENT WORKFLOW] Closing event loop")
                    try:
                        loop.close()
                    except Exception as close_err:
                        logger.warning(f"[CONTENT WORKFLOW] Error closing loop: {close_err}")

            thread = threading.Thread(target=execute_in_background, daemon=True)
            thread.start()

            return ContentWorkflowResponse(
                work_request_id=work_request_id,
                work_ticket_id=work_ticket_id,
                status="running",
                outputs=[],
                execution_time_ms=None,
                message="Content generation started in background - track progress via work_ticket status",
                recipe_used=recipe.slug if recipe else None,
            )

        # SYNC MODE: Execute and wait for result
        logger.info(f"[CONTENT WORKFLOW] Sync mode: executing content generation")

        # Update status to running
        supabase.table("work_tickets").update({
            "status": "running",
            "started_at": datetime.now(timezone.utc).isoformat(),
        }).eq("id", work_ticket_id).execute()

        # Build enhanced task if recipe-driven
        enhanced_task = request.task_description
        if execution_context:
            task_breakdown = execution_context.get("task_breakdown", [])
            deliverable_intent = execution_context.get("deliverable_intent", {})
            enhanced_task = f"""**Recipe: {recipe.name}**

**Deliverable Intent:**
- Purpose: {deliverable_intent.get('purpose', 'Create content')}
- Audience: {deliverable_intent.get('audience', 'Target audience')}
- Outcome: {deliverable_intent.get('outcome', 'Quality content')}

**Task:** {request.task_description}

**Task Breakdown:**
{chr(10).join([f"- {step}" for step in task_breakdown])}

**Parameters:**
- Platform: {validated_params.get('platform', request.content_type)}
- Tone: {validated_params.get('tone', request.tone)}
- Topic: {validated_params.get('topic_focus', request.task_description)}

{execution_context.get('system_prompt_additions', '')}
"""

        # Create executor via factory (Gemini or Anthropic based on provider)
        executor = get_content_agent(
            basket_id=request.basket_id,
            workspace_id=workspace_id,
            work_ticket_id=work_ticket_id,
            user_id=user_id,
            user_jwt=user_token,
            provider=request.provider,
        )

        start_time = time.time()

        # Execute based on provider type
        from agents.gemini_content_agent import GeminiContentAgent
        if isinstance(executor, GeminiContentAgent):
            # Gemini agent (text + image)
            result = await executor.execute(
                task=enhanced_task,
                content_type=request.content_type,
                tone=request.tone,
                target_audience=request.target_audience,
                brand_voice=request.brand_voice,
                include_image=request.include_image,
                image_style=request.image_style,
                create_variants=request.create_variants,
                variant_count=request.variant_count,
            )
        else:
            # Anthropic agent (text only)
            result = await executor.execute(
                task=enhanced_task,
                content_type=request.content_type,
                tone=request.tone,
                target_audience=request.target_audience,
                brand_voice=request.brand_voice,
                create_variants=request.create_variants,
                variant_count=request.variant_count,
                enable_web_search=request.enable_web_search,
            )
        execution_time_ms = int((time.time() - start_time) * 1000)

        # Update to completed
        supabase.table("work_tickets").update({
            "status": "completed",
            "completed_at": datetime.now(timezone.utc).isoformat(),
            "metadata": {
                "workflow": "recipe_content" if recipe else "deterministic_content",
                "execution_time_ms": execution_time_ms,
                "output_count": len(result.work_outputs),
                "recipe_slug": recipe.slug if recipe else None,
                "token_usage": {
                    "input_tokens": result.input_tokens,
                    "output_tokens": result.output_tokens,
                    "cache_read_tokens": result.cache_read_tokens,
                },
            },
        }).eq("id", work_ticket_id).execute()

        logger.info(
            f"[CONTENT WORKFLOW] Complete: {len(result.work_outputs)} outputs "
            f"in {execution_time_ms}ms, tokens={result.input_tokens}+{result.output_tokens}"
        )

        return ContentWorkflowResponse(
            work_request_id=work_request_id,
            work_ticket_id=work_ticket_id,
            status="completed",
            outputs=result.work_outputs,
            execution_time_ms=execution_time_ms,
            message=f"Content complete: {len(result.work_outputs)} outputs generated",
            recipe_used=recipe.slug if recipe else None,
            token_usage={
                "input_tokens": result.input_tokens,
                "output_tokens": result.output_tokens,
                "cache_read_tokens": result.cache_read_tokens,
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[CONTENT WORKFLOW] Failed: {e}")

        if 'work_ticket_id' in locals():
            try:
                supabase.table("work_tickets").update({
                    "status": "failed",
                    "completed_at": datetime.now(timezone.utc).isoformat(),
                    "metadata": {
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "recipe_slug": recipe.slug if recipe and 'recipe' in locals() else None,
                    },
                }).eq("id", work_ticket_id).execute()
            except Exception as update_error:
                logger.error(f"Failed to update work_ticket status: {update_error}")

        raise HTTPException(
            status_code=500,
            detail=f"Content workflow execution failed: {str(e)}"
        )
